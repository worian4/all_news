import re
import hashlib
import torch
from sentence_transformers import SentenceTransformer
import logging

logger = logging.getLogger(__name__)

class NeuralNewsProcessor:
    def __init__(self):
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        
        try:
            # –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫) –Ω–∞ GPU
            self.embedding_model = SentenceTransformer(
                'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                device=self._setup_gpu()
            )
            
            logger.info("‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            raise

    def _setup_gpu(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π"""
        try:
            if torch.cuda.is_available():
                device = torch.device("cuda")
                gpu_name = torch.cuda.get_device_name(0)
                logger.info(f"üéÆ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {gpu_name}")
            else:
                device = torch.device("cpu")
                logger.info("‚ùå GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
            return device
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPU: {e}")
            return torch.device("cpu")

    def create_fingerprint(self, text):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –æ—Ç–ø–µ—á–∞—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        if not text or len(text.strip()) < 10:
            return "0" * 64
            
        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞ GPU
            embedding = self.embedding_model.encode(text, convert_to_tensor=True)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ö—ç—à
            embedding_np = embedding.cpu().numpy()
            embedding_bytes = embedding_np.tobytes()
            return hashlib.sha256(embedding_bytes).hexdigest()
        except Exception as e:
            logger.error(f"Error creating fingerprint: {e}")
            return hashlib.sha256(text.encode('utf-8')).hexdigest()

    def calculate_interest_score(self, text):
        """–û—Ü–µ–Ω–∫–∞ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞"""
        if not text or len(text.strip()) < 20:
            return 0.0
        
        try:
            scores = []
            
            # 1. –û—Ü–µ–Ω–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
            length_score = min(len(text) / 500, 1.0) * 0.3
            
            # 2. –û—Ü–µ–Ω–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Å–ª–æ–≤
            words = text.split()
            if len(words) > 0:
                unique_words = set(words)
                diversity_score = len(unique_words) / len(words)
                scores.append(diversity_score * 0.3)
            
            # 3. –û—Ü–µ–Ω–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–µ–∫—Å—Ç–∞
            structure_score = self._calculate_structure_score(text)
            scores.append(structure_score * 0.4)
            
            total_score = length_score + sum(scores)
            return min(total_score, 1.0)
            
        except Exception as e:
            logger.error(f"Error calculating interest score: {e}")
            return 0.5

    def _calculate_structure_score(self, text):
        """–û—Ü–µ–Ω–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞"""
        score = 0.0
        
        # –ù–∞–ª–∏—á–∏–µ —á–∏—Å–µ–ª
        if any(char.isdigit() for char in text):
            score += 0.2
        
        # –ù–∞–ª–∏—á–∏–µ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤
        if any(char.isupper() for char in text):
            score += 0.2
        
        # –î–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        sentences = re.split(r'[.!?]+', text)
        if len(sentences) > 0:
            avg_sentence_length = sum(len(sent.split()) for sent in sentences) / len(sentences)
            if 5 <= avg_sentence_length <= 20:
                score += 0.3
        
        # –ù–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π
        news_keywords = ['–Ω–æ–≤–æ—Å—Ç—å', '—Å–æ–±—ã—Ç–∏–µ', '—Å–æ–æ–±—â–µ–Ω–∏–µ', '–∑–∞—è–≤–ª–µ–Ω–∏–µ', '–∏–Ω—Ç–µ—Ä–≤—å—é', 
                        '–∞–Ω–∞–ª–∏–∑', '–¥–∞–Ω–Ω—ã–µ', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ', '—ç–∫—Å–ø–µ—Ä—Ç', '–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ']
        if any(keyword in text.lower() for keyword in news_keywords):
            score += 0.3
            
        return min(score, 1.0)

    def are_posts_similar(self, fingerprint1, fingerprint2):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–≤—É—Ö –ø–æ—Å—Ç–æ–≤"""
        return fingerprint1 == fingerprint2